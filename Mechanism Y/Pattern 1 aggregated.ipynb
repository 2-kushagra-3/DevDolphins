{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abee6266-d9e3-4a5b-8bc7-faac65473ec5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, avg, lit, expr, when, coalesce\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, DoubleType, TimestampType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "customer_df = (\n",
    "    spark.read.option(\"header\", \"true\")\n",
    "    .csv(\"abfss://gdrive-ingest@devdolphinstorage.dfs.core.windows.net/reference_data/customer data.csv\")\n",
    ")\n",
    "\n",
    "\n",
    "merchant_transaction_count_df = spark.createDataFrame([], \"merchant STRING, total_txn LONG\")\n",
    "customer_merchant_stats_df = spark.createDataFrame([], \"customer STRING, merchant STRING, txn_count LONG, avg_weight DOUBLE\")\n",
    "\n",
    "transactions_schema = StructType([\n",
    "    StructField(\"step\", LongType(), True),\n",
    "    StructField(\"customer\", StringType(), True),\n",
    "    StructField(\"age\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"zipcodeOri\", StringType(), True),\n",
    "    StructField(\"merchant\", StringType(), True),\n",
    "    StructField(\"zipMerchant\", StringType(), True),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"amount\", DoubleType(), True),\n",
    "    StructField(\"fraud\", LongType(), True),\n",
    "])\n",
    "\n",
    "transactions_df = (\n",
    "    spark.readStream\n",
    "    .option(\"header\", True)\n",
    "    .schema(transactions_schema)\n",
    "    .csv(\"abfss://gdrive-ingest@devdolphinstorage.dfs.core.windows.net/transactions/\")\n",
    ")\n",
    "\n",
    "\n",
    "def foreach_batch_function(batch_df, batch_id):\n",
    "    global merchant_transaction_count_df\n",
    "    global customer_merchant_stats_df\n",
    "\n",
    "    print(f\"âš¡ Processing batch {batch_id} rows: {batch_df.count()}\")\n",
    "\n",
    "    #  Join with static reference\n",
    "    merged_df = (\n",
    "        batch_df.join(\n",
    "            customer_df,\n",
    "            (batch_df[\"customer\"] == customer_df[\"Source\"]) &\n",
    "            (batch_df[\"merchant\"] == customer_df[\"Target\"]) &\n",
    "            (batch_df[\"category\"] == customer_df[\"typeTrans\"]) &\n",
    "            (batch_df[\"amount\"] == customer_df[\"Weight\"]),\n",
    "            \"inner\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if merged_df.isEmpty():\n",
    "        print(f\"ðŸš« No matching transactions for this batch.\")\n",
    "        return\n",
    "\n",
    "    #  Update merchant_transaction_count_df\n",
    "    merchant_txn = merged_df.groupBy(\"merchant\").count().withColumnRenamed(\"count\", \"new_txn_count\")\n",
    "\n",
    "    if merchant_transaction_count_df.isEmpty():\n",
    "        merchant_transaction_count_df = merchant_txn.withColumnRenamed(\"new_txn_count\", \"total_txn\")\n",
    "    else:\n",
    "        left_df = merchant_transaction_count_df.withColumnRenamed(\"total_txn\", \"left_total_txn\")\n",
    "        right_df = merchant_txn.withColumnRenamed(\"new_txn_count\", \"right_new_txn_count\")\n",
    "\n",
    "        merchant_transaction_count_df = (\n",
    "            left_df.join(right_df, on=\"merchant\", how=\"outer\")\n",
    "            .fillna(0)\n",
    "            .withColumn(\"total_txn\", col(\"left_total_txn\") + col(\"right_new_txn_count\"))\n",
    "            .select(\"merchant\", \"total_txn\")\n",
    "        )\n",
    "\n",
    "    print(f\" Updated merchant_transaction_count_df count: {merchant_transaction_count_df.count()}\")\n",
    "\n",
    "    #  Update customer_merchant_stats_df\n",
    "    cust_stats = (\n",
    "        merged_df.groupBy(\"customer\", \"merchant\")\n",
    "        .agg(\n",
    "            count(\"step\").alias(\"new_txn_count\"),\n",
    "            avg(\"Weight\").alias(\"new_avg_weight\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if customer_merchant_stats_df.isEmpty():\n",
    "        customer_merchant_stats_df = cust_stats.withColumnRenamed(\"new_txn_count\", \"txn_count\").withColumnRenamed(\"new_avg_weight\", \"avg_weight\")\n",
    "    else:\n",
    "        left_df = customer_merchant_stats_df.withColumnRenamed(\"txn_count\", \"left_txn_count\").withColumnRenamed(\"avg_weight\", \"left_avg_weight\")\n",
    "        right_df = cust_stats.withColumnRenamed(\"new_txn_count\", \"right_txn_count\").withColumnRenamed(\"new_avg_weight\", \"right_avg_weight\")\n",
    "\n",
    "        customer_merchant_stats_df = (\n",
    "            left_df.join(right_df, on=[\"customer\", \"merchant\"], how=\"outer\")\n",
    "            .fillna(0)\n",
    "            .withColumn(\n",
    "                \"txn_count\",\n",
    "                col(\"left_txn_count\") + col(\"right_txn_count\")\n",
    "            )\n",
    "            .withColumn(\n",
    "                \"avg_weight\",\n",
    "                ((col(\"left_avg_weight\") * col(\"left_txn_count\")) + (col(\"right_avg_weight\") * col(\"right_txn_count\"))) /\n",
    "                when(col(\"left_txn_count\") + col(\"right_txn_count\") == 0, 1).otherwise(col(\"left_txn_count\") + col(\"right_txn_count\"))\n",
    "            )\n",
    "            .select(\"customer\", \"merchant\", \"txn_count\", \"avg_weight\")\n",
    "        )\n",
    "\n",
    "    print(f\" Updated customer_merchant_stats_df count: {customer_merchant_stats_df.count()}\")\n",
    "\n",
    "    detections = []\n",
    "    merchants = merchant_transaction_count_df.collect()\n",
    "\n",
    "    for row in merchants:\n",
    "        if row[\"total_txn\"] < 50000:\n",
    "            continue\n",
    "\n",
    "        merchant = row[\"merchant\"]\n",
    "        subset = customer_merchant_stats_df.filter(col(\"merchant\") == merchant)\n",
    "\n",
    "        if subset.isEmpty():\n",
    "            continue\n",
    "\n",
    "        txn_thresh = subset.approxQuantile(\"txn_count\", [0.9], 0.01)[0]\n",
    "        weight_thresh = subset.approxQuantile(\"avg_weight\", [0.1], 0.01)[0]\n",
    "\n",
    "        eligible = subset.filter(\n",
    "            (col(\"txn_count\") >= txn_thresh) &\n",
    "            (col(\"avg_weight\") <= weight_thresh)\n",
    "        ).withColumn(\"YStartTime\", F.current_timestamp()) \\\n",
    "         .withColumn(\"detectionTime\", F.current_timestamp()) \\\n",
    "         .withColumn(\"patternId\", lit(\"PatId1\")) \\\n",
    "         .withColumn(\"ActionType\", lit(\"UPGRADE\")) \\\n",
    "         .withColumnRenamed(\"customer\", \"customerName\") \\\n",
    "         .withColumnRenamed(\"merchant\", \"MerchantId\") \\\n",
    "         .select(\"YStartTime\", \"detectionTime\", \"patternId\", \"ActionType\", \"customerName\", \"MerchantId\")\n",
    "        eligible.show(truncate=False)\n",
    "        \n",
    "\n",
    "    print(\" Pattern 1 batch done!\")\n",
    "\n",
    "# -----------------------------------\n",
    "# Start Streaming Query\n",
    "# -----------------------------------\n",
    "query = (\n",
    "    transactions_df.writeStream\n",
    "    .foreachBatch(foreach_batch_function)\n",
    "    .start()\n",
    ")\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pattern 1 aggregated",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
