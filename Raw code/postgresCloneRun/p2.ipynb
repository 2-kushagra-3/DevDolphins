{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ec189d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Processing: chunk_10_20250624_202551.csv\n",
      "ðŸ“¦ Processing: chunk_11_20250624_202553.csv\n",
      "ðŸ“¦ Processing: chunk_1_20250624_202535.csv\n",
      "ðŸ“¦ Processing: chunk_2_20250624_202537.csv\n",
      "ðŸ“¦ Processing: chunk_3_20250624_202539.csv\n",
      "ðŸ“¦ Processing: chunk_4_20250624_202540.csv\n",
      "ðŸ“¦ Processing: chunk_5_20250624_202542.csv\n",
      "ðŸ“¦ Processing: chunk_6_20250624_202544.csv\n",
      "ðŸ“¦ Processing: chunk_7_20250624_202546.csv\n",
      "ðŸ“¦ Processing: chunk_8_20250624_202548.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_27424\\1684371362.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ).fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Processing: chunk_9_20250624_202550.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ§  Simulated PostgreSQL Table\n",
    "# -----------------------------\n",
    "customer_merchant_amount_df = pd.DataFrame(columns=[\n",
    "    \"customer\", \"merchant\", \"txn_count\", \"total_amount\"\n",
    "])\n",
    "\n",
    "# Optional: Set to track already detected customer-merchant pairs\n",
    "already_detected = set()\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ”„ Update State from a Chunk\n",
    "# -----------------------------\n",
    "def update_postgres_sim(chunk_df):\n",
    "    global customer_merchant_amount_df\n",
    "\n",
    "    stats = chunk_df.groupby(['customer', 'merchant']).agg(\n",
    "        txn_count=('amount', 'count'),\n",
    "        total_amount=('amount', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    customer_merchant_amount_df_combined = pd.merge(\n",
    "        customer_merchant_amount_df,\n",
    "        stats,\n",
    "        on=['customer', 'merchant'],\n",
    "        how='outer'\n",
    "    ).fillna(0)\n",
    "\n",
    "    customer_merchant_amount_df_combined['txn_count'] = (\n",
    "        customer_merchant_amount_df_combined['txn_count_x'] + customer_merchant_amount_df_combined['txn_count_y']\n",
    "    )\n",
    "\n",
    "    customer_merchant_amount_df_combined['total_amount'] = (\n",
    "        customer_merchant_amount_df_combined['total_amount_x'] + customer_merchant_amount_df_combined['total_amount_y']\n",
    "    )\n",
    "\n",
    "    customer_merchant_amount_df = customer_merchant_amount_df_combined[\n",
    "        ['customer', 'merchant', 'txn_count', 'total_amount']\n",
    "    ]\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ” Detect Pattern 2\n",
    "# -----------------------------\n",
    "def detect_pattern2():\n",
    "    detections = []\n",
    "\n",
    "    customer_merchant_amount_df['avg_amount'] = (\n",
    "        customer_merchant_amount_df['total_amount'] / customer_merchant_amount_df['txn_count']\n",
    "    )\n",
    "\n",
    "    # Apply pattern logic\n",
    "    filtered = customer_merchant_amount_df[\n",
    "        (customer_merchant_amount_df['txn_count'] >= 80) &\n",
    "        (customer_merchant_amount_df['avg_amount'] < 23)\n",
    "    ]\n",
    "\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    for _, row in filtered.iterrows():\n",
    "        key = (row['customer'], row['merchant'])\n",
    "        if key in already_detected:\n",
    "            continue  # Avoid duplicates\n",
    "\n",
    "        detection = {\n",
    "            \"YStartTime\": now,\n",
    "            \"detectionTime\": now,\n",
    "            \"patternId\": \"PatId2\",\n",
    "            \"ActionType\": \"CHILD\",\n",
    "            \"customerName\": row['customer'],\n",
    "            \"MerchantId\": row['merchant'],\n",
    "            \"txn_count\": int(row['txn_count']),\n",
    "        }\n",
    "        detections.append(detection)\n",
    "        already_detected.add(key)\n",
    "\n",
    "    return pd.DataFrame(detections)\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ’¾ Write Detections\n",
    "# -----------------------------\n",
    "def write_detections(detections, output_dir=\"outputs/\", file_prefix=\"detections_pat2\"):\n",
    "    if detections.empty:\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for i in range(0, len(detections), 50):\n",
    "        batch = detections.iloc[i:i+50]\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "        output_path = f\"{output_dir}/{file_prefix}_{timestamp}.csv\"\n",
    "        batch.to_csv(output_path, index=False)\n",
    "        print(f\"âœ… Wrote {len(batch)} detections to {output_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸš€ Main Function\n",
    "# -----------------------------\n",
    "def main():\n",
    "    chunk_folder = r\"C:\\Users\\kusha\\OneDrive\\Desktop\\Projects\\DevDolphins\\Blob files\\Chunks\"\n",
    "    all_files = sorted(os.listdir(chunk_folder))\n",
    "\n",
    "    for file in all_files:\n",
    "        print(f\"ðŸ“¦ Processing: {file}\")\n",
    "        chunk_df = pd.read_csv(os.path.join(chunk_folder, file))\n",
    "\n",
    "        chunk_df['amount'] = chunk_df['amount'].astype(float)\n",
    "\n",
    "        update_postgres_sim(chunk_df)         # Update rolling stats\n",
    "        detections_df = detect_pattern2()     # Detect based on full state\n",
    "        write_detections(detections_df)       # Write in batches\n",
    "\n",
    "# -----------------------------\n",
    "# ðŸ” Entry Point\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f8b608c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            customer       merchant  txn_count  total_amount  avg_amount\n",
      "5373   'C1598564853'   'M348934600'       40.0        924.00   23.100000\n",
      "5688    'C164104645'  'M1823072687'       39.0       1098.08   28.155897\n",
      "777    'C1087943403'  'M1823072687'       39.0       1013.65   25.991026\n",
      "1295   'C1145304322'   'M348934600'       39.0        986.51   25.295128\n",
      "10223  'C2144163136'   'M348934600'       39.0       1160.90   29.766667\n",
      "...              ...            ...        ...           ...         ...\n",
      "16     'C1002658784'   'M855959430'        1.0         47.58   47.580000\n",
      "15     'C1002658784'   'M348934600'        1.0         18.09   18.090000\n",
      "14     'C1002658784'  'M1888755466'        1.0         71.71   71.710000\n",
      "13     'C1002658784'  'M1741626453'        1.0        197.30  197.300000\n",
      "11     'C1001065306'    'M50039827'        1.0        188.94  188.940000\n",
      "\n",
      "[16828 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(customer_merchant_amount_df.sort_values(\"txn_count\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac316f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
