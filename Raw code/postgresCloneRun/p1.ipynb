{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbafb730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: chunk_10_20250624_202551.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_37700\\3718385650.py:38: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ).fillna(0)\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_37700\\3718385650.py:53: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ).fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: chunk_1_20250624_202535.csv\n",
      "Processing: chunk_2_20250624_202537.csv\n",
      "Processing: chunk_3_20250624_202539.csv\n",
      "Processing: chunk_4_20250624_202540.csv\n",
      "Processing: chunk_5_20250624_202542.csv\n",
      "Processing: chunk_6_20250624_202544.csv\n",
      "Processing: chunk_7_20250624_202546.csv\n",
      "Processing: chunk_8_20250624_202548.csv\n",
      "Processing: chunk_9_20250624_202550.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# -----------------------------\n",
    "#  Simulated Postgres Tables\n",
    "# -----------------------------\n",
    "merchant_transaction_count_df = pd.DataFrame(columns=[\"merchant\", \"total_txn\"])\n",
    "customer_merchant_stats_df = pd.DataFrame(columns=[\"customer\", \"merchant\", \"txn_count\", \"avg_weight\"])\n",
    "\n",
    "# -----------------------------\n",
    "#  Load Customer Importance\n",
    "# -----------------------------\n",
    "customer_df = pd.read_csv(r\"C:\\Users\\kusha\\OneDrive\\Desktop\\Projects\\DevDolphins\\Blob files\\customer data\\customer data.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "#  Process One Chunk\n",
    "# -----------------------------\n",
    "def process_chunk(chunk_df):\n",
    "    global merchant_transaction_count_df\n",
    "    global customer_merchant_stats_df\n",
    "\n",
    "    # Step 1: Merge with customer importance to get Weight\n",
    "    merged_df = chunk_df.merge(\n",
    "        customer_df,\n",
    "        how='inner',\n",
    "        left_on=['customer', 'merchant', 'category', 'amount'],\n",
    "        right_on=['Source', 'Target', 'typeTrans', 'Weight']\n",
    "    )\n",
    "\n",
    "    # Step 2: Update merchant-level transaction count\n",
    "    merchant_txn = merged_df.groupby('merchant').size().reset_index(name='new_txn_count')\n",
    "    merchant_transaction_count_df = pd.merge(\n",
    "        merchant_transaction_count_df,\n",
    "        merchant_txn,\n",
    "        on='merchant',\n",
    "        how='outer'\n",
    "    ).fillna(0)\n",
    "    merchant_transaction_count_df['total_txn'] = merchant_transaction_count_df['total_txn'] + merchant_transaction_count_df['new_txn_count']\n",
    "    merchant_transaction_count_df.drop(columns=['new_txn_count'], inplace=True)\n",
    "\n",
    "    # Step 3: Update customer-merchant level stats (txn_count + avg_weight)\n",
    "    cust_merchant_stats = merged_df.groupby(['customer', 'merchant']).agg(\n",
    "        txn_count=('step', 'count'),\n",
    "        avg_weight=('Weight', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    customer_merchant_stats_df = pd.merge(\n",
    "        customer_merchant_stats_df,\n",
    "        cust_merchant_stats,\n",
    "        on=['customer', 'merchant'],\n",
    "        how='outer'\n",
    "    ).fillna(0)\n",
    "\n",
    "    customer_merchant_stats_df['txn_count'] = customer_merchant_stats_df['txn_count_x'] + customer_merchant_stats_df['txn_count_y']\n",
    "    customer_merchant_stats_df['avg_weight'] = (\n",
    "        (customer_merchant_stats_df['avg_weight_x'] * customer_merchant_stats_df['txn_count_x']) +\n",
    "        (customer_merchant_stats_df['avg_weight_y'] * customer_merchant_stats_df['txn_count_y'])\n",
    "    ) / customer_merchant_stats_df['txn_count']\n",
    "\n",
    "    customer_merchant_stats_df = customer_merchant_stats_df[['customer', 'merchant', 'txn_count', 'avg_weight']]\n",
    "\n",
    "# -----------------------------\n",
    "#  Pattern 1 Detection Logic\n",
    "# -----------------------------\n",
    "def detect_patid1():\n",
    "    detections = []\n",
    "\n",
    "    for merchant in merchant_transaction_count_df.itertuples():\n",
    "        if merchant.total_txn < 50000:\n",
    "            continue\n",
    "\n",
    "        merchant_name = merchant.merchant\n",
    "        cust_subset = customer_merchant_stats_df[\n",
    "            customer_merchant_stats_df['merchant'] == merchant_name\n",
    "        ]\n",
    "\n",
    "        if cust_subset.empty:\n",
    "            continue\n",
    "\n",
    "        txn_threshold = cust_subset['txn_count'].quantile(0.90)\n",
    "        weight_threshold = cust_subset['avg_weight'].quantile(0.10)\n",
    "\n",
    "        eligible = cust_subset[\n",
    "            (cust_subset['txn_count'] >= txn_threshold) &\n",
    "            (cust_subset['avg_weight'] <= weight_threshold)\n",
    "        ]\n",
    "\n",
    "        for row in eligible.itertuples():\n",
    "            detections.append({\n",
    "                \"YStartTime\": \"\",  # optional if you want to track start of ingestion\n",
    "                \"detectionTime\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                \"patternId\": \"PatId1\",\n",
    "                \"ActionType\": \"UPGRADE\",\n",
    "                \"customerName\": row.customer,\n",
    "                \"MerchantId\": row.merchant\n",
    "            })\n",
    "\n",
    "    return detections\n",
    "\n",
    "# -----------------------------\n",
    "#  Write Detections (50 per file)\n",
    "# -----------------------------\n",
    "def write_detections(detections, output_dir=\"outputs/\", file_prefix=\"detections_pat1\"):\n",
    "    if not detections:\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for i in range(0, len(detections), 50):\n",
    "        batch = detections[i:i+50]\n",
    "        df = pd.DataFrame(batch)\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "        df.to_csv(f\"{output_dir}/{file_prefix}_{timestamp}.csv\", index=False)\n",
    "\n",
    "# -----------------------------\n",
    "#  Main Loop\n",
    "# -----------------------------\n",
    "def main():\n",
    "    # Use raw string (r\"\") to avoid escape issues\n",
    "    chunk_folder = r\"C:\\Users\\kusha\\OneDrive\\Desktop\\Projects\\DevDolphins\\Blob files\\Chunks\"\n",
    "    all_files = sorted(os.listdir(chunk_folder))\n",
    "\n",
    "    for file in all_files:\n",
    "        print(f\"Processing: {file}\")\n",
    "        chunk_df = pd.read_csv(os.path.join(chunk_folder, file))\n",
    "\n",
    "        # Ensure numeric types are correct\n",
    "        chunk_df['amount'] = chunk_df['amount'].astype(float)\n",
    "\n",
    "        process_chunk(chunk_df)\n",
    "        detections = detect_patid1()\n",
    "        write_detections(detections)\n",
    "\n",
    "# -----------------------------\n",
    "#  Entry Point\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3418c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>merchant</th>\n",
       "      <th>txn_count</th>\n",
       "      <th>avg_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'C1000148617'</td>\n",
       "      <td>'M1888755466'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'C100045114'</td>\n",
       "      <td>'M1198415165'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'C100045114'</td>\n",
       "      <td>'M151143676'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'C100045114'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'C100045114'</td>\n",
       "      <td>'M480139044'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15763</th>\n",
       "      <td>'C999393223'</td>\n",
       "      <td>'M2122776122'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15764</th>\n",
       "      <td>'C999393223'</td>\n",
       "      <td>'M480139044'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>476.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15765</th>\n",
       "      <td>'C999393223'</td>\n",
       "      <td>'M855959430'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15766</th>\n",
       "      <td>'C999723254'</td>\n",
       "      <td>'M1535107174'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15767</th>\n",
       "      <td>'C999723254'</td>\n",
       "      <td>'M1888755466'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15768 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            customer       merchant  txn_count  avg_weight\n",
       "0      'C1000148617'  'M1888755466'        1.0      143.87\n",
       "1       'C100045114'  'M1198415165'        1.0       33.98\n",
       "2       'C100045114'   'M151143676'        1.0       64.99\n",
       "3       'C100045114'   'M348934600'        4.0       26.27\n",
       "4       'C100045114'   'M480139044'        1.0       35.88\n",
       "...              ...            ...        ...         ...\n",
       "15763   'C999393223'  'M2122776122'        1.0       61.42\n",
       "15764   'C999393223'   'M480139044'        1.0      476.43\n",
       "15765   'C999393223'   'M855959430'        1.0       10.77\n",
       "15766   'C999723254'  'M1535107174'        1.0       17.43\n",
       "15767   'C999723254'  'M1888755466'        1.0      101.41\n",
       "\n",
       "[15768 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_merchant_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c8b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
