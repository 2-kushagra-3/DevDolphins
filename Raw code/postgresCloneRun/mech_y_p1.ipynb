{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "595810aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ded783a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_transaction_count_df = pd.DataFrame(columns=[\"merchant\", \"total_txn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "af8581b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_merchant_stats_df = pd.DataFrame(columns=[\"customer\", \"merchant\", \"txn_count\", \"avg_weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "91cb7364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk_df, customer_df):\n",
    "    global merchant_transaction_count_df\n",
    "    global customer_merchant_stats_df\n",
    "\n",
    "    # Step 0: Join with CustomerImportance to get Weight\n",
    "    merged_df = chunk_df.merge(\n",
    "        customer_df,\n",
    "        how='inner',\n",
    "        left_on=['customer', 'merchant', 'category', 'amount'],\n",
    "        right_on=['Source', 'Target', 'typeTrans', 'Weight']\n",
    "    )\n",
    "\n",
    "    # Step 1: Update merchant-level transaction count\n",
    "    merchant_txn = merged_df.groupby('merchant').size().reset_index(name='new_txn_count')\n",
    "    merchant_transaction_count_df = pd.merge(\n",
    "        merchant_transaction_count_df,\n",
    "        merchant_txn,\n",
    "        on='merchant',\n",
    "        how='outer'\n",
    "    ).fillna(0)\n",
    "    merchant_transaction_count_df['total_txn'] = merchant_transaction_count_df['total_txn'] + merchant_transaction_count_df['new_txn_count']\n",
    "    merchant_transaction_count_df.drop(columns=['new_txn_count'], inplace=True)\n",
    "\n",
    "    # Step 2: Update customer-merchant stats (count + avg weight)\n",
    "    cust_merchant_stats = merged_df.groupby(['customer', 'merchant']).agg(\n",
    "        txn_count=('step', 'count'),\n",
    "        avg_weight=('Weight', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    customer_merchant_stats_df = pd.merge(\n",
    "        customer_merchant_stats_df,\n",
    "        cust_merchant_stats,\n",
    "        on=['customer', 'merchant'],\n",
    "        how='outer'\n",
    "    ).fillna(0)\n",
    "\n",
    "    customer_merchant_stats_df['txn_count'] = customer_merchant_stats_df['txn_count_x'] + customer_merchant_stats_df['txn_count_y']\n",
    "    customer_merchant_stats_df['avg_weight'] = (\n",
    "        (customer_merchant_stats_df['avg_weight_x'] * customer_merchant_stats_df['txn_count_x']) +\n",
    "        (customer_merchant_stats_df['avg_weight_y'] * customer_merchant_stats_df['txn_count_y'])\n",
    "    ) / customer_merchant_stats_df['txn_count']\n",
    "\n",
    "    customer_merchant_stats_df = customer_merchant_stats_df[['customer', 'merchant', 'txn_count', 'avg_weight']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "17bb4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_patid1():\n",
    "    detections = []\n",
    "\n",
    "    for merchant in merchant_transaction_count_df.itertuples():\n",
    "        if merchant.total_txn < 50000:\n",
    "            continue\n",
    "\n",
    "        merchant_name = merchant.merchant\n",
    "        cust_subset = customer_merchant_stats_df[\n",
    "            customer_merchant_stats_df['merchant'] == merchant_name\n",
    "        ]\n",
    "\n",
    "        if cust_subset.empty:\n",
    "            continue\n",
    "\n",
    "        txn_threshold = cust_subset['txn_count'].quantile(0.90)\n",
    "        weight_threshold = cust_subset['avg_weight'].quantile(0.10)\n",
    "\n",
    "        eligible = cust_subset[\n",
    "            (cust_subset['txn_count'] >= txn_threshold) &\n",
    "            (cust_subset['avg_weight'] <= weight_threshold)\n",
    "        ]\n",
    "\n",
    "        for row in eligible.itertuples():\n",
    "            detections.append({\n",
    "                \"YStartTime\": \"\",  # to be filled in if known\n",
    "                \"detectionTime\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                \"patternId\": \"PatId1\",\n",
    "                \"ActionType\": \"UPGRADE\",\n",
    "                \"customerName\": row.customer,\n",
    "                \"MerchantId\": row.merchant\n",
    "            })\n",
    "\n",
    "    return detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d40bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Path to the directory containing chunk files\n",
    "# folder_path = r\"C:\\Users\\kusha\\OneDrive\\Desktop\\Projects\\DevDolphins\\Blob files\\Chunks\"\n",
    "\n",
    "# # List all CSV files in the folder\n",
    "# csv_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# # Read and concatenate all CSVs into one DataFrame\n",
    "# transactions_df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "\n",
    "transactions_df = pd.read_csv(r\"C:\\Users\\kusha\\OneDrive\\Desktop\\Projects\\DevDolphins\\Blob files\\Chunks\\chunk_1_20250624_202535.csv\")\n",
    "customer_df = pd.read_csv(r\"C:\\Users\\kusha\\OneDrive\\Desktop\\Projects\\DevDolphins\\Blob files\\customer data\\customer data.csv\")\n",
    "customer_df\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
